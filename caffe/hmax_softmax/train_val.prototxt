# # Changes for Rule & Riesenhuber:
# - delete GoogLeNet & just use InnerProduct followed by softmax classification
# - classifiers: num_outputs = 2000 rather than 1000 to support the 2,000-
#   category conceptual vocabulary
# - multi_gpu: batch_size = 120
name: "hmax_conceptual_layer"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
  }
  data_param {
    source: "/data2/image_sets/image_net/feat_train_hmax_lmdb"
    batch_size: 120
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
  }
  data_param {
    source: "/data2/image_sets/image_net/feat_val_hmax_lmdb"
    batch_size: 120 
    backend: LMDB
  }
}
layer {
  name: "dropout"
  type: "Dropout"
  bottom: "data"
  top: "data"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "classifier"
  type: "InnerProduct"
  bottom: "data"
  top: "classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss/softmax"
  type: "SoftmaxWithLoss"
  bottom: "classifier"
  bottom: "label"
  top: "loss/softmax"
  loss_weight: 1
}
layer {
  name: "loss/top-1"
  type: "Accuracy"
  bottom: "classifier"
  bottom: "label"
  top: "loss/top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "loss/top-5"
  type: "Accuracy"
  bottom: "classifier"
  bottom: "label"
  top: "loss/top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
